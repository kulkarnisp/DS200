@article{Chandola2009AnomalyDA,
  title={Anomaly detection: A survey},
  author={V. Chandola and A. Banerjee and V. Kumar},
  journal={ACM Comput. Surv.},
  year={2009},
  volume={41},
  pages={15:1-15:58}
}

@book{CharuOUtlier,
author = {Aggarwal, Charu C.},
title = {Outlier Analysis},
year = {2013},
isbn = {1461463955},
publisher = {Springer Publishing Company, Incorporated},
abstract = {With the increasing advances in hardware technology for data collection, and advances in software technology (databases) for data organization, computer scientists have increasingly participated in the latest advancements of the outlier analysis field. Computer scientists, specifically, approach this field based on their practical experiences in managing large amounts of data, and with far fewer assumptions the data can be of any type, structured or unstructured, and may be extremely large. Outlier Analysisis a comprehensive exposition, as understood by data mining experts, statisticians and computer scientists. The book has been organized carefully, and emphasis was placed on simplifying the content, so that students and practitioners can also benefit. Chapters will typically cover one of three areas: methods and techniques commonly used in outlier analysis, such as linear methods, proximity-based methods, subspace methods, and supervised methods; data domains, such as, text, categorical, mixed-attribute, time-series, streaming, discrete sequence, spatial and network data; and key applications of these methods as applied to diverse domains such as credit card fraud detection, intrusion detection, medical diagnosis, earth science, web log analytics, and social network analysis are covered.}
}


@inproceedings{Tax2001OneclassC,
  title={One-class classification},
  author={D. Tax},
  year={2001}
}

@inproceedings{Hempstalk2008OneClassCB,
  title={One-Class Classification by Combining Density and Class Probability Estimation},
  author={K. Hempstalk and Eibe Frank and I. Witten},
  booktitle={ECML/PKDD},
  year={2008}
}

@article{Fawcett2006AnIT,
  title={An introduction to ROC analysis},
  author={T. Fawcett},
  journal={Pattern Recognit. Lett.},
  year={2006},
  volume={27},
  pages={861-874}
}

@inbook{Kolla2020,
	abstract = {We propose the use of higher order tensors, and their decompositions, for efficient analysis of combustion direct numerical simulation (DNS) data. Turbulent data set is examined.},
	address = {Cham},
	author = {Kolla, Hemanth
	and Aditya, Konduri
	and Chen, Jacqueline H.},
	booktitle = {Data Analysis for Direct Numerical Simulations of Turbulent Combustion: From Equation-Based Analysis to Machine Learning},
	doi = {10.1007/978-3-030-44718-2_6},
	editor = {Pitsch, Heinz
	and Attili, Antonio},
	isbn = {978-3-030-44718-2},
	pages = {109--134},
	publisher = {Springer International Publishing},
	title = {Higher Order Tensors for DNS Data Analysis and Compression},
	url = {https://doi.org/10.1007/978-3-030-44718-2_6},
	year = {2020}
}


@article{ADITYA2019isml,
	abstract = {We propose an anomaly detection method for multi-variate scientific data based on analysis of high-order joint moments. Using kurtosis as a reliable measure of outliers, we suggest that principal kurtosis vectors, by analogy to principal component analysis (PCA) steps.},
	author = {Konduri Aditya and Hemanth Kolla and W. Philip Kegelmeyer and Timothy M. Shead and Julia Ling and Warren L. Davis},
	doi = {https://doi.org/10.1016/j.jcp.2019.03.003},
	issn = {0021-9991},
	journal = {Journal of Computational Physics},
	keywords = {Anomaly detection, Scientific computing, Co-kurtosis, Tensor decomposition, Hellinger distance, Auto-ignition},
	pages = {522 - 538},
	title = {Anomaly detection in scientific data using joint statistical moments},
	url = {http://www.sciencedirect.com/science/article/pii/S002199911930172X},
	volume = {387},
	year = {2019}
}


@inproceedings{LingTSNE,
	author = {Wu, Jinlong and Wang, Jian-Xun and Xiao, Heng and Ling, Julia},
	year = {2017},
	month = {01},
	pages = {},
	title = {Visualization of High Dimensional Turbulence Simulation Data using t-SNE},
	doi = {10.2514/6.2017-1770}
}

@article{LingRANS,
	author = {Ling, J. and Templeton, Jeremy},
	year = {2015},
	month = {08},
	pages = {085103},
	title = {Evaluation of machine learning algorithms for prediction of regions of high Reynolds averaged Navier Stokes uncertainty},
	volume = {27},
	journal = {Physics of Fluids},
	doi = {10.1063/1.4927765}
}


@inproceedings{Ling2017Feature,
	abstract = {With current high performance scientific computing workflows, data are typically recorded at regular intervals spaced several hundred time steps apart. Data are not saved at every time step to prevent excessive memory usage and because data I/O is often a bottleneck in the workflow. However, in many dynamical systems, events of interest occur locally in space and time. In these cases, a global data save across all processors at regular intervals is both inefficient and ineffective: it will result in data being saved over regions where nothing of interest is occurring, and it will miss an event of interest that occurs at time steps between data saves. What is needed is a method of automatically detecting an event of interest as it occurs so that a data save can be triggered on the relevant processors. We propose a method of detecting such events of interest using feature importance metrics. This method requires very little communication between processors, thereby lending itself to implementation in a high performance computing setting.},
	author = {J. Ling and W. P. Kegelmeyer and K. Aditya and H. Kolla and K. A. Reed and T. M. Shead and W. L. Davis},
	booktitle = {2017 IEEE 7th Symposium on Large Data Analysis and Visualization (LDAV)},
	doi = {10.1109/LDAV.2017.8231851},
	month = {Oct},
	pages = {55-63},
	title = {Using feature importance metrics to detect events of interest in scientific computing applications},
	year = {2017}
}

@incollection{NIPSoSVM,
title = {Support Vector Method for Novelty Detection},
author = {Sch\"{o}lkopf, Bernhard and Williamson, Robert C and Alex J. Smola and John Shawe-Taylor and John C. Platt},
booktitle = {Advances in Neural Information Processing Systems 12},
editor = {S. A. Solla and T. K. Leen and K. M\"{u}ller},
pages = {582--588},
year = {2000},
publisher = {MIT Press},
url = {http://papers.nips.cc/paper/1723-support-vector-method-for-novelty-detection.pdf}
}


@article{Liu2008IsolationF,
  title={Isolation Forest},
  author={F. Liu and K. Ting and Z. Zhou},
  journal={2008 Eighth IEEE International Conference on Data Mining},
  year={2008},
  pages={413-422}
}

@article{Goldstein2016ACE,
  title={A Comparative Evaluation of Unsupervised Anomaly Detection Algorithms for Multivariate Data},
  author={Markus Goldstein and S. Uchida},
  journal={PLoS ONE},
  year={2016},
  volume={11}
}

@inproceedings{Sydney2019DeepLF,
  title={Deep Learning for Anomaly Detection: A Survey},
  author={Raghavendra Chalapathy University of Sydney and Capital Markets Cooperative Research Centre and Sanjay Chawla Qatar Computing Research Institute and Hbku},
  year={2019}
}

@inproceedings{DataDrivenJulia,
	author = {Ling, Julia and Kurzawski, Andrew},
	year = {2017},
	month = {06},
	pages = {},
	title = {Data-driven Adaptive Physics Modeling for Turbulence Simulations},
	doi = {10.2514/6.2017-3627}
}

@article{Domino2018MultivariateCI,
	title={Multivariate cumulants in features selection and outlier detection for financial data analysis},
	author={Krzysztof Domino},
	journal={arXiv: Methodology},
	year={2018}
}

@article{kurtosisRIP,
	author = {Peter H. Westfall},
	title = {Kurtosis as Peakedness, 1905–2014. R.I.P.},
	journal = {The American Statistician},
	volume = {68},
	number = {3},
	pages = {191-195},
	year  = {2014},
	publisher = {Taylor & Francis},
	doi = {10.1080/00031305.2014.917055},
	
	URL = { 
	https://doi.org/10.1080/00031305.2014.917055
	
	},
	eprint = { 
	https://doi.org/10.1080/00031305.2014.917055
	
	}
	,
	abstract = { The incorrect notion that kurtosis somehow measures “peakedness” (flatness, pointiness, or modality) of a distribution is remarkably persistent, despite attempts by statisticians to set the record straight. This article puts the notion to rest once and for all. Kurtosis tells you virtually nothing about the shape of the peak—its only unambiguous interpretation is in terms of tail extremity, that is, either existing outliers (for the sample kurtosis) or propensity to produce outliers (for the kurtosis of a probability distribution). To clarify this point, relevant literature is reviewed, counterexample distributions are given, and it is shown that the proportion of the kurtosis that is determined by the central μ ± σ range is usually quite small. }
}

@article{kurtosisMeaning,
	author = { J. J. A.   Moors },
	title = {The Meaning of Kurtosis: Darlington Reexamined},
	journal = {The American Statistician},
	volume = {40},
	number = {4},
	pages = {283-284},
	year  = {1986},
	publisher = {Taylor & Francis},
	doi = {10.1080/00031305.1986.10475415},
	
	URL = { 
	https://www.tandfonline.com/doi/abs/10.1080/00031305.1986.10475415
	
	},
	eprint = { 
	https://www.tandfonline.com/doi/pdf/10.1080/00031305.1986.10475415
	
	}
	,
	abstract = { Abstract There seems to be no universal agreement about the meaning and interpretation of kurtosis. An easy interpretation is given here: kurtosis is a measure of dispersion around the two values μ ± σ. }
}


@article{BHAGATWALA20141826,
	title = "Direct numerical simulations of HCCI/SACI with ethanol",
	journal = "Combustion and Flame",
	volume = "161",
	number = "7",
	pages = "1826 - 1841",
	year = "2014",
	issn = "0010-2180",
	doi = "https://doi.org/10.1016/j.combustflame.2013.12.027",
	url = "http://www.sciencedirect.com/science/article/pii/S0010218014000030",
	author = "Ankit Bhagatwala and Jacqueline H. Chen and Tianfeng Lu",
	keywords = "HCCI, SACI, Thermal stratification, Mixture stratification, Premixed flame, Autoignition",
	abstract = "Two and three dimensional direct numerical simulations (DNS) of an autoignitive premixture of air and ethanol in Homogeneous Charge Compression Ignition (HCCI) mode"
}