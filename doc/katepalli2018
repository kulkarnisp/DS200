
https://www.pnas.org/content/116/18/8667
Deep learning in turbulent convection networks
Enrico Fonda, Ambrish Pandey, Jörg Schumacher, and Katepalli R. Sreenivasan
PNAS April 30, 2019 116 (18) 8667-8672; first published April 15, 2019; https://doi.org/10.1073/pnas.1900358116

We explore heat transport properties of turbulent Rayleigh–Bénard convection in horizontally extended systems by using deep-learning algorithms that greatly reduce the number of degrees of freedom. Particular attention is paid to the slowly evolving turbulent superstructures—so called because they are larger in extent than the height of the convection layer—which appear as temporal patterns of ridges of hot upwelling and cold downwelling fluid, including defects where the ridges merge or end. The machine-learning algorithm trains a deep convolutional neural network (CNN) with U-shaped architecture, consisting of a contraction and a subsequent expansion branch, to reduce the complex 3D turbulent superstructure to a temporal planar network in the midplane of the layer. This results in a data compression by more than five orders of magnitude at the highest Rayleigh number, and its application yields a discrete transport network with dynamically varying defect points, including points of locally enhanced heat flux or “hot spots.” One conclusion is that the fraction of heat transport by the superstructure decreases as the Rayleigh number increases (although they might remain individually strong), correspondingly implying the increased importance of small-scale background turbulence.

Weakness
1. The time series nature of simulations is not incorporated in the given network settings and thus any short lived abnormalities might be missed by the model.
2. Model improvements with more efficient representation ability could have been possible with state of the art vision models such as generative networks.


Weakness
1. The time series nature of simulations is not incorporated in the given network settings and thus any short lived abnormalities might be missed by the model.
2. Model improvements with more efficient representation ability could have been possible with state of the art vision models such as generative networks.

